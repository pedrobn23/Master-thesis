

\chapter{Lambda Calculus}
\thispagestyle{empty}
In this chapter we define the $\lambda$-calculus as a formal language of computation, and on this define the concept of typing, ubiquitous in programming. The main references  for the general approach if this chapter are are \cite{selinger2008lecture} and \cite{hindley2008lambda}. For the historical motivation for the development of the theory  we refer to \cite{cardone2006history}.  \\


In the 19th century mathematicians developed the concept of function. In this time it was question whether two functions were the same. The most widespread view is the \emph{extensional} approach. This approach consider two functions to be the same whenever for the same input they have the same output. A function $f$ as a pairing of an X domain to an Y codomain. These functions can be considered as sets $f\subset X \times Y$.\\

Despite that, this notion can be considered misleading. For example, let $p$ be a prime big enough, and let $f$ and $g$ be two endomorphisms of  $\mathbb{Z}/p\mathbb{Z}$. One could argue that the endomorphism of  $f(x)\to x^2$ is different to $g(x) \to \log_a a^{x+2}$. Despite having the same output for the same input, they are clearly different in \emph{complexity}, with complexity understood as the cost of computing a function. It even involve the resolution of a discrete logarithm, that is highly non trivial. \\

This view, in which not only is the result of the function important but how is that result obtained, is called the \emph{intensional} approach. This approach, gain traction in early 1930 as Church\cite{church1932set}, GÃ¶del\cite{adams2011early} or Turing\cite{turing1938computable} start formalizing what is to be computable. Nowadays, after the wake of computation, the intensional approach have come to be as relevant as the extenisional approach.

% (to the point on which correctness is often partially dropped to easy time complexity, for example \cite{hofmeister2002probabilistic}). \\

% In $\lambda$-calculus we consider function as formulas, and thus, we consider an intensional approach. This intensional approach was also backed by the constructivist, to whom we will later on relate with the study of the Curry-Howard isomorphism  .\\


\section{Untyped $\lambda$-Calculus }
We will start defining the most simple version of $\lambda$-calculus: untyped $\lambda$-calculus. Let's define some concepts:


\begin{enumerate}
\item An alphabet $A$ is an arbitrary, maybe finite, non-empty set.
\item A symbol $a$ in an element of the alphabet.
\item A word is a finite sequence of symbols.
\item The collection of all possible finite words over an alphabet $A$ is denoted by $A^*$.
\item A language $L$ over $A$  is a subset of $A^*.$
\end{enumerate}

There are a lot of languages. For example, Spanish is a language, with a well-known alphabet $L$, with a proper subset of words over $L^*$.In the same fashion, we define $\lambda$-calculus as a formal language, defining its syntax, that is, what words are valid.


\subsubsection{Syntax of untyped $\lambda$-calculus}
We start with the basic building blocks, which collectively form what is
called the alphabet:

\begin{itemize}
\item We use $x, y, z,...$ to denote variables. As more variables are necessary sub-indexes will be used, up to countable infinite variables.
\item We consider an abstract connector $\lambda$.
\item Auxiliary, we consider the characters $".", "("$ and $")"$.
\end{itemize}
Now, we are ready to formally define the untyped $\lambda$-calculus:

\begin{definition}[Syntax of Untyped $\lambda$-calculus (section 2.1 \cite{selinger2008lecture})]\label{def:untyped-lambda-calc}
  A $\lambda$-calculus term (sometimes called formula) is defined inductively:
  \begin{itemize}
  \item Every variable $x,y,z...$ is a valid formula.
  \item If $A,B$ is a formula, then $AB$ is a valid formula.
  \item If $A$ is a formula and $x$ is a variable, then $\lambda x.M$ is a valid formula.
  \end{itemize}
  The set of all variables is denoted by $\mathcal{V}$ and the set of all $\lambda$-formulas is denoted by $\Lambda$.
\end{definition}
\begin{remark}
  $\Lambda$ is countable.
\end{remark}

Dealing with formal languages we make use of similar inductive statements more often than not. we find it useful to introduce the Backus-Naur Form notation \cite{knuth1964backus}, BNF for short.  A BNF specification is a set of derivation rules, written as
$$\operatorname{word1}, \operatorname{word2} ... ::= \operatorname{expression1} | \operatorname{expression2} |...,$$
where each $\operatorname{word}$ is a generic valid word from the language, and each  expression consists of a derived valid formulas. Expressions are separated by the vertical bar: $|$. For example, we can revisit definition \ref{def:untyped-lambda-calc} as follow:

\begin{definition}
  The formulas of  $\lambda$-calculus are built via the BNF:
  $$A,B ::= x\ |\ (AB)\ |\ (\lambda x.A) .$$
  where $x$ denote any variable in $\mathcal{V}$.
\end{definition}
\begin{remark}
  Note that there is no need to specify the alphabet aside from the set $\mathcal{V}$.
\end{remark}

From this point on we know how the $\lambda$-terms are constructed. This point is better understood with some examples, using natural numbers.  We recommend to trust us in their existence, and use a naive intuition of what a natural is when  reading this examples. The notion of natural numbers is formalized definition \ref{def:untyped-natural} and revisited in section \ref{section:natural-revisited}.\\

\subsection{Reductions in untyped $\lambda$-calculus}
Let us now explain the idea behind the formalism. Consider the expression $\lambda x.(x+1)$. This expression represent the idea of the function $f(x)=x+1$ that take a variable $x$ and return $x+1$. $\lambda x.M$ is called the \emph{abstraction} of $x$.\\

From the notion of abstraction naturally arises the second one: \emph{application}. Consider terms $M  =\lambda x. x+1$ and $N = 3$. Then $MN = (\lambda x. x+1)(3)$ represent the application of $M$ to $N$. In untyped $\lambda$-calculus, $N$ can be any term. Thus for example, the term $\lambda f.\lambda g. fg$ just represent the composition of terms.   

\begin{example} The term $$\lambda g.(\lambda f.(\lambda x. (gf)(x) )) (x+1)(x+2),$$
  can be understood as $(g\circ f) (x)$ where $g(x) = x+1$ and $f(x)=x+2$.
\end{example}

In a expression $M = (\lambda x. N)$ we say that the variable $x$ is \emph{bound} in $M$.


The idea of $\alpha$-equivalence, $=_{\alpha}$, is that expressions such as $\lambda x.x$ and $\lambda y.y$ are essentially the same. That is, we consider terms up to \emph{rename} of variables. To formalise this, we have to formalize the concept of free and bound variables, and the concept of renamed.

\begin{definition}
  We have a \emph{free variable} function $FV:\Lambda \to \mathcal{P}(\mathcal{V})$ defined recursively:
  \begin{itemize}
  \item $FV(x) = \{x\}$ for every $x\in \mathcal{V}$.
  \item $FV(MN) = FV(M)\cap FV(N)$ for every $M,N\in \Lambda$.
  \item $FV(\lambda x.M) = FV(M)\backslash \{x\}$ for every $M\in \Lambda, x\in \mathcal{V}$.
  \end{itemize}
  Given a term $M$, if $x\in FV(M)$ we say that $x$ is a free variable in $M$ or that $M$ has a free variable $x$.
\end{definition}

\begin{definition}
  We say that a term is \emph{closed} if it has no free variables.
\end{definition}
We can now define process of \emph{substitution}, and define a rename as a particular case. This process is the one behind the intuitive idea of evaluation. For example when we consider $(\lambda y. y^2+y)(4) = 4^2+4 = 20$ we are replacing the value of $x$ by the term $4$. 
\begin{definition}\label{def:substition}
  The substitution of $N$ for free occurrences of $x$ in $M$, denoted as $M[N/x]$ is defined recurrently in the structure of $\lambda$-terms by:
  \begin{align*}
    x[N/x]& \equiv N,\\
    y[N/x]& \equiv y, &  \text{if } x\ne y&,\\
    (MP)[N/x]& \equiv (M[N/x])(P[N/x]),\\
    (\lambda x.M)[N/x] & \equiv \lambda x.M,\\
    (\lambda y.M)[N/x] & \equiv \lambda y.(M[N/x]), & \text{if } x\ne y \text{ and } \not \in FV(N)&,\\
    (\lambda y.M)[N/x] & \equiv \lambda y'.((M[y'/y])[N/x]), & \text{if } x\ne y \text{ and } y\in FV(N),\\
          & & \text{ with } y' \not \in FV(N) \cup \{x\}&.
  \end{align*}
  When $N = y$ a variable we say that $[N/x] = [y/x]$ is a rename. 
\end{definition}

\begin{definition}
  We define the $\alpha$-equivalence $=_\alpha$ as the smallest congruence relation on $\Lambda$ such that:
  $$\lambda x. M =_\alpha \lambda y. M[x/y], \qquad \forall y \in \mathcal{V} \backslash FV(M).$$
\end{definition}
In other words is the congruence that consider every rename of a bounded variable as equals. This type of property-oriented definition is commonplace in $\lambda$-calculus, as it allows for some synthetic and goal-oriented definition. More often than note we will not give explicit use of this equivalence.\\



Using this same tool we are going to define the $\beta$-reduction. This is not going to be an equivalence implication, but rather a relationship. It abstracts the notion of $4$ and $(\lambda x. 2+x)(2)$ being equals. Formally:

\begin{definition}[Section 2.5 \cite{selinger2008lecture}]
  We define the \emph{single-step} $\beta$\emph{-reduction} as the smallest relationship $\to_\beta$ such that:%\footnote{Should i explain the notation ${A \over B}$}
  \begin{align*}
    &(\beta) \qquad\ \ \  \ {\ \over(\lambda x.M)N \to_\beta M[N/x]},\\
    &(\operatorname{cong}_1)\qquad\qquad{ M \to_\beta M' \over MN \to_\beta M'N },\\
    &(\operatorname{cong}_2)\qquad\qquad{ N \to_\beta N' \over MN \to_\beta MN' },\\
    &(\zeta) \qquad\qquad \ \  \ {M\to_\beta M' \over(\lambda x.M) \to_\beta \lambda x.M'}.\\
  \end{align*}
\end{definition}

\begin{remark}
  In this definition we can see that rule $(\beta)$ is the main objective, while the others are necessary so that it maintain the structure.
\end{remark}
\begin{definition}
  We define the \emph{multiple-step} $\beta$\emph{-reduction} $\twoheadrightarrow_\beta$ as the reflexive, transitive closure of $\to_\beta$.
\end{definition}
\begin{definition}
  We define the $\beta$-equivalence $=_\beta$ as the symmetric closure of $\twoheadrightarrow_\beta$.
\end{definition}

Up to this point the focus of the system was to define an intensional language for computation. $\beta$-reduction encapsulate the concept of computation, where we have evaluation.

\begin{example}
  \begin{itemize}
  \item Ending example.
  \item Never ending example.
  \end{itemize}
\end{example}


Should we want to consider a way of having an extensional approach, for example, to generate normal forms for the terms, we would need more machinery. The $\eta$-equivalence provides us with the tools to consider $\lambda$-calculus in a extensional way. \\

\begin{definition}
  We define the single-step $\eta$-reduction $\to_\eta$ as the smallest relationship such that: 
  \begin{align*}
    &(\eta) \qquad\qquad \ \ \ \  \ {\ \over(\lambda x.Mx) \to_\eta M} \qquad \forall x \not  \in FV(M),\\
    &(\operatorname{cong}_1)\qquad\qquad{ M \to_\eta M' \over MN \to_\eta M'N },\\
    &(\operatorname{cong}_2)\qquad\qquad{ N \to_\eta N' \over MN \to_\eta MN' },\\
    &(\zeta) \qquad\qquad \ \  \ {M\to_\eta M' \over(\lambda x.M) \to_\eta \lambda x.M'}.\\
  \end{align*}
  Similarly, we define the multiple-step $\eta$-reduction $\twoheadrightarrow_\eta$ as the transitive reflexive closure of $\to_\eta$, and the $\eta$-equivalence as the symmetric closure of $\twoheadrightarrow_\eta$.
\end{definition}
\begin{definition}
  We define the single-step $\beta\eta$-reduction $\to_{\beta\eta}$ as the union of $\to_\beta$ and $\to_\eta$.  We define the multiple-step $\beta\eta$-reduction $\twoheadrightarrow_{\beta\eta}$ as the transitive reflexive closure of $\to_{\beta\eta}$.
\end{definition}

% \begin{proposition}
%   In the presence of all other axioms defined in $\beta$ and $\eta$ equivalences, $\eta$ rule is equivalent to:\footnote{TODO: Revisar si es equivalencia o reducciÃ³n.}
%   $$(ext) \qquad\ \ \  \ {\ (Mx=M'x)\text{ where } x\not\in FV(M)\cup FV(M') \over M \to_\eta M' \land M' \to_\eta M} $$
% \end{proposition}
% \begin{proof}
%   By extenisionality we have that $M' = $.
% \end{proof}


% \begin{remark}
%   This proof that the $\eta$-reduction maintain extensionality in some sense. Also, note that we need to consider $\eta$-equivalence and not only $\eta$-reduction.
% \end{remark}

\begin{table}[h]
  \begin{center}
    \begin{tabular}{|l|l|l|}
      \hline
      Name & Main rule & Equivalence \\
      \hline
      $\alpha$ & $ (\lambda x. M) =_\alpha \lambda y. M[x/y]$& Yes\\
      $\beta$ & $(\lambda x.M)N \to_\beta M[N/x]$& No\\
      $\eta$ & ${\displaystyle (\lambda x.Mx) \to_\eta M }$& No\\
      \hline
    \end{tabular}
  \end{center}
  \caption{\label{tab:reductions}Reductions}
\end{table}


\subsection{Church-Rosser Theorem}

This subsection we present an important result for $\lambda$-calculus: the \emph{Church-Rosser} theorem. The idea behind this theorem is to prove that every reduction (either $\beta$, $\eta$ or a mix) provide an unified sense of reduction. First, we present some definitions.

\begin{definition}
  Consider a relation $\to$ and let $\twoheadrightarrow$ be its reflexive transitive closure. We can define three relations:

  \begin{enumerate}
  \item The Church-Rosser Property: $$M\twoheadrightarrow N, M\twoheadrightarrow P \implies \exists Z : N\twoheadrightarrow Z, P\twoheadrightarrow Z.$$
  \item The Quasidiamond Property: $$M\to N, M\to P \implies \exists Z : N\twoheadrightarrow Z, P\twoheadrightarrow Z.$$
  \item The Diamond Property : $$M\to N, M\to P \implies \exists Z : N\to Z,P\to Z$$
  \end{enumerate}
\end{definition}

\begin{remark} 
  Note that, while $3)\implies 1)$, it is not necessary that $2)\implies 1)$.
\end{remark}


With this notation, we introduce the Church-Rosser Theorem, proved as done by Martin-LÃ¶f.

\begin{theorem}{Church-Rosser}\label{theo:church-rosser}
  \begin{enumerate}
  \item $\twoheadrightarrow_{\beta\eta}$ satisfy the Church-Rosser property.
  \item $\twoheadrightarrow_{\beta}$ satisfy the Church-Rosser property.
  \end{enumerate}
\end{theorem}




We prove the theorem only for the $ \twoheadrightarrow_{\beta\eta}$ case. We refer to [Theorem 1.32, \cite{hindley2008lambda}] for a full proof for $\twoheadrightarrow_\beta$. he first step in the proof is going to be an alternative definition of $\toheadrightarrow_{\beta\eta}$, as a completion of a new reduction $\triangleright$.
\begin{definition}[parallel one-step reduction]
  We define the parallel one-step reduction  $\triangleright$ as the smallest relationship such that,\\
  \begin{align*}
    (1)&& {\displaystyle \over x \triangleright x}\qquad\qquad\qquad\qquad\qquad\\
    (2)&& { M \triangleright M'\qquad N\triangleright N'  \over MN \triangleright M'N' }\qquad\qquad\qquad\ \  \ \\
    (3)&&{M \triangleright M' \over(\lambda x.M) \triangleright \lambda x.M'}\qquad\qquad\qquad\qquad\\
    (4)&& {M \triangleright M'\qquad N \triangleright N' \over (\lambda x.M)N \triangleright M'[N'/x]}\qquad\qquad\qquad\\
    (5)&& {\ M\triangleright M'\over(\lambda x.Mx) \triangleright M'} \qquad \forall x \not  \in FV(M)\qquad
  \end{align*}



  where $x$ is any variable and $M,N,M',N'$ any term.
\end{definition}

\begin{lemma}[Characterization of $\triangleright$]\label{lemma:cr1}
  Let $M,M'$ be terms, then:
  \begin{enumerate}
  \item $M\to_{\beta\eta} M'\implies M \triangleright M'$
  \item $M\triangleright M'\implies M \twoheadrightarrow_{\beta\eta} M'$
  \end{enumerate}
\end{lemma}
\begin{proof}
  \begin{enumerate}
  \item  We  apply induction on the structure of $\to_{\beta\eta}$. That is, we know that $\to_{\beta\eta}$ have to be constructed following a series of rules. We are going to use induction on the last rule used. Therefore we conclude  every rule use for $\M \to_{\beta\eta} M'$ implies $M \triangleright M'$.

    \begin{itemize}
    \item[($\beta$)] In this case, then $M=(\lambda x.Q)M$ and $M' = Q[N/x]$. Then using (4) $M \triangleright M'$.
    \item[($\eta$)] In this case, then $M=(\lambda x.Qx)$ and $M' = Q$. Then using (5) $M \triangleright M'$.
    \item[($\operatorname{cong}_1$)] In this case, then $M=PQ$ and $M' = PQ'$ for some $Q\to_{\beta\eta} Q'$. Using induction $Q\triangleright Q'$ and using (5) $M \triangleright M'$. 
    \item[($\operatorname{cong}_2$)]  Analogous.
    \item[($\zeta$)] In this case, then $M=\lambda x.Q$ and $M' = \lambda x.Q'$ for some $Q\to_{\beta\eta} Q'$. Using induction $Q\triangleright Q'$ and using (3) $M \triangleright M'$.  
    \end{itemize}
    Where, in every point, $x$ denote some variable, and $M,N,M',N',P,Q,Q'$ denote some term.
  \item Similarly, every possible in which $M\triangleright M'$ rule derive in  $M \twoheadrightarrow_{\beta\eta} M'$:
    \begin{itemize}
    \item[(1)] By reflexivity of $ \twoheadrightarrow_{\beta\eta}$.
    \item[(2)] By $\operatorname{cong}_1,\operatorname{cong}_2$ in either definition of $\to_\beta$ and $\to_\eta$.
    \item[(3)] By $\zeta$ in either definition of $\to_\beta$ and $\to_\eta$.
    \item[(4)] Then we have $(\lambda x.M)N \triangleright M'[N'/x]$ with $M \triangleright M'\qquad N \triangleright N'$. By induction $M \twoheadrightarrow_{\beta\eta} M'$ and $N \twoheadrightarrow_{\beta\eta} N'$. By transitive closure:
      $$(\lambda x.M)N \twoheadrightarrow_{\beta\eta}(\lambda x.M')N \twoheadrightarrow_{\beta\eta} (\lambda x.M')N' \twoheadrightarrow_{\beta\eta} (M')[N'/x].$$
    \item[(5)] Then we have $(\lambda x.Mx) \triangleright M'$, for some $M\triangleright M'$ and for some $x \not  \in FV(M)$. Finish using $(\operatorname{cong}_2)$ and $\eta$.
    \end{itemize}

  \end{enumerate}
  Where, in every point, $x$ denote some variable, and $M,N,M',N',P,Q,Q'$ denote some term.
\end{proof}

\begin{lemma}[Subtitution Lemma]If $M \triangleright M'$ and $U \triangleright U'$ , then $M [U/y] \triangleright M' [U' /y]$.
\end{lemma}
\begin{proof}
  As we define in \ref{def:substition} a capture-avoiding substitution, in the sense that we do not let bound variable to be substituted, we can assume without any loss of generality that $M$. Similarly to previous lemma, we proceed by induction, studying the last rule applied. The induction is proceed on the rules applied to $M\triangleright M'$.

  \begin{itemize}
  \item[(1)] In this case $M=M'=x$. If $x\ne y$ the substitution does not alter $M$ so we have finished. If $x = y$, the term is only $U\triangleright U'$, that we know by hypothesis.
  \item[(2)] In this case $M=NP, M'=P'N'$ for some terms $N,N',P,P'$ such that $N\triangleright N'$, $P\triangleright P'$. Proceed by induction on these implications and apply (2).
  \item[(3)] In this case $M=\lambda x.N$ and $M=\lambda x.N'$, for some $N\triangleright N'$. Apply induction on $N$ and end by (3).
  \item[(4)] Then we have $(\lambda x.M)N \triangleright M'[N'/x]$ with $M \triangleright M'$ and $N \triangleright N'$. By induction on both of the relationship, and applying (4).
  \item[(5)] Then we have $(\lambda x.Mx) \triangleright M'$, for some $M\triangleright M'$ and for some $x \not  \in FV(M)$. Finish using induction on $M\triangleright M'$ and by (5).
  \end{itemize}
\end{proof}

While the proof is rather straight forward, one can see that it does require induction, and thus the length of it. \footnote{Maybe add some explanation here.}

\begin{definition}[Maximal parallel one-step reduction]
  Given a term $M$, the \emph{maximal parallel one-step reduction} $M^*$ is defined inductively:
  \begin{itemize}
  \item $(x)^*  =x$ 
  \item $(PN)*=P^*N^*$ but for $\beta$-reductions.
  \item $((\lambda x.P)N)^* = Q^*[N/x] $
  \item $(\lambda x.N)^*=\lambda x.N^*$ but for $\eta$-reductions, 
  \item $(\lambda x.Nx)^*=N^*$ 
  \end{itemize}
  where $x$ is any variable, and $N,P$ is any term.
\end{definition}


\begin{lemma}[Maximal Parallel one-step]\label{lemma:cr2}
  If $M\triangleright M'$ then $M'\triangleright M^*$.
\end{lemma}
\begin{proof}
  \begin{itemize}
  We proceed by induction on $M$ again:
\item[(1)] In this case $M=M'=x$. Then $M^*=x$.
\item[(2)] In this case $M=NP, M'=P'N'$ for some terms $N,N',P,P'$ such that $N\triangleright N'$, $P\triangleright P'$.
  \begin{itemize}
  \item If $NP$ is not a $\beta$-reduction, then $M^* = P^*N^*$ and we can use the hypothesis induction on $N^*$ and $P^*$ and (2).
  \item If $NP$ is a $\beta$-reduction, then $N = \lambda x. Q$, thus $M^* = Q^*[N^*/x]$. $P = \lambda x.Q$ and $P \triangleright P'$ could be derived using congruence to $\lambda$-abstraction (2) or extensionality (5). In the first case use induction on $Q$ and (4). On the second case $Q=Rx$, use induction on $R$, and apply substitution lemma.
  \end{itemize}

  Proceed by induction on these implications and apply (2).
\item[(3)] In this case $M=\lambda x.N$ and $M=\lambda x.N'$, for some $N\triangleright N'$. If $M$ is not an $\eta$-reduction, then use induction hypothesis and finish with (3). Otherwise we have that $N = Py$, and distinguish two cases on the last rule applied to $N$:
  \begin{itemize}
  \item[(2)\to (3)] Then apply induction hypothesis to $P$ and end using (5).
  \item[(4)\to (3)] We have that $N = P = \lambda y.Q \triangleright N' = Q'[x/y]$. Apply induction hypothesis using that $M ' = \lambda x.N' = \lambda x.Q'[x/y] = \lambda y. Q'$.
  \end{itemize}
\item[(4)] Then we have $(\lambda x.P)N \triangleright P'[N'/x]$ with $P \triangleright P'$ and $P \triangleright P'$. By substitution lemma.
\item[(5)] Then we have $(\lambda x.Px) \triangleright P'$, for some $P\triangleright P'$ and for some $x \not  \in FV(P)$. Finish using induction on 
\end{itemize}
\end{proof}


\begin{proof}[Proof of Theorem \ref{theo:church-rosser}]   If a relation $\to$ satisfy the diamond property, its reflexive, transitive closure $\twoheadrightarrow$ satisfy the Church-Rosser property. As a consequence of lemma \ref{lemma:cr2}, we know that $\triangleright$ satisfy the diamond property.  By lemma \ref{lemma:cr1} we know that the reflexive, transitive closure of $\triangleright$ is $\twoheadrightarrow_{\beta\eta}$.
\end{proof}

Now let take a moment to comment on the usefulness of each reduction. We can say that $\beta$ reduction is the soul of computation  while $\eta$ is useful to cleanup the results.  This can be used to define \emph{normal} forms for untyped lambda-terms. More infomation on normalization can be found on \cite[Section 7]{selinger2008lecture} and \cite{baader1999term}. \\


\subsection{Fixed points and Programming}
In this subsection we expose the basic rudiments for programming in untyped $\lambda$-calculus. In particular, we explain how to define, for example, a booleans, an integer type and a recursion operator, thus showing the computational potential of recursively enumerable languages. We start with the booleans.

\begin{definition}[Boolean in untyped lambda-calculus] \label{def:untyped-natural} 
  We define the two values $T$ and $F$, true and false, as:
  \begin{align*}
    \operatorname{True} &= \lambda xy.z,\\
    \operatorname{False} &= \lambda xy.z.
  \end{align*}
  We also define the operations:
  \begin{align*}
    \operatorname{Not} &= \lambda a.a\operatorname{False}\operatorname{True},\\
    \operatorname{And} &= \lambda ab.ab\operatorname{False},\\
    \operatorname{Or} &= \lambda ab.a\operatorname{True}b.
  \end{align*}
\end{definition}

We can check that this construction left us with the basis of a boolean logic, after checking the truth values of the different operations provided. This definition of truth value is really convenient, as it allow us to easily implement control flow of programs.

\begin{definition}
  We define the $\operatorname{If} = \lambda x.x$.  
\end{definition}

We can see that in this case, $\operatorname{If} \operatorname{True} M N = M$ and $\operatorname{If} \operatorname{False} M N = N$. This construction is very natural and widely used in computer programs. Next, we will define Naturals number. 

\begin{definition}[Natural numbers in untyped lambda-calculus] \label{def:untyped-natural} 
  Let $f,x$ be fixed $\lambda$-terms, and write $f^nx = f(f(f(...(f(x))...)))$. Then, for each $n \in \mathbb N$, we define the \emph{nth Church numeral} as $\overline n=\lambda fx.f^nx$.
\end{definition}

Finally, we consider the notion of recursive function. This is done with a elegant artefact, based on an idea of fixed points. Let's begin:



\begin{theorem}[Fixed points]
  For every term $F$ in untyped $\lambda$-calculus, there is a fixed point.
\end{theorem}
\begin{proof}
  Let $A=\lamdba xy.y(xxy)$ and $\Theta =AA$. Then, for every lambda-term $F$ we have that $N=\theta F = FN$, thus being a fixed point. In fact:
  \begin{align*}
    N = \Theta F = AAF = (\lambda xy.y(xxy))AF \twoheadrightarrow_\beta F(AAF) = F(\Theta F) = FN.
  \end{align*}
\end{proof}
The proof of this theorem led to a new definition:

\begin{definition}
  The term $\Theta$ used in the previous theorem is called \emph{Turing fixed point combinator}.
\end{definition}

This existence of fixed point theorem is really useful, as we can now define \emph{recursion}. The idea is to define a function as a term with itself as a parameters and proceed to evaluate a fixed point. Let us first present an example.

\begin{definition}
  We define the terms:
  \begin{align*}
    \operatorname{add} &= \lambda nm f x.nf (mf x),\\
    \operatorname{mult} &= \lambda nm f.n(mf),\\
    \operatorname{iszero} &= \lambda nxy.n(\lambda z.y)x,\\
    \operatorname{predecesor} &=\lambda n.\lambda f.\lambda x. n (\lambda g.\lambda h. h (g f)) (\lambda u.x) (\lambda u.u). 
  \end{align*}
  
\end{definition}
Suppose that we want to define the factorial. We want that:
$$\operatorname{fact} n = \operatorname{If}(\operatorname{iszero} n)(1)(\operatorname{mult}(n)(\operatorname{fact} (\operatorname{pred}(n))),$$
in orther to do that, look for a fixed point of:
$$\lambda f. \lambda n.\operatorname{If}(\operatorname{iszero}n)(1)(\operatorname{mult}(n)(f (\operatorname{pred}(n))),$$
and thus $\operatorname{fact}=\Theta \lambda f.\lambda n. \operatorname{If}(\operatorname{iszero}n)(1)(\operatorname{mult}(n)(f (\operatorname{pred}(n)))$. In general:

\begin{definition}
  Given an stop condition $g$, an stop value $s$ and a recursive step $f$, we define the recursive term $F$ that computes $(g,s,f)$ as
  $$F = \Theta \lambda f. \operatorname{If}(gn)(n)(f (\operatorname{pred}(n))$$
\end{definition}

Another implementation of the fixed point operator is \emph{Curry's paradoxical fixed point operator}:

\begin{definition}
  We define Curry's paradoxical fixed point operator $\operatorname{Y}$ as:
  $$\operatorname{Y}=\lambda f.(\lambda x.f(x x)) (\lambda x.f(x x)).$$
\end{definition}

This operator is used for the Curry's paradox \cite{sep-curry-paradox}.\\

% \subsection{Rosser-Kleene and Curry's Paradoxes}

% In this subsection we explain the deficits in untyped $\lambda$-calculus, that was the original Church construction, that eventually leads into the definition of \emph{typed} $\lambda$-\emph{calculus}.\\


% We can start by having a quick reasoning, as shown in \cite{sep-lambda-calculus}.


% {TODO This Summer: expand this subsection properly.}

% An aproximation of this argument can be done if we consider domains of functions to be sets. In particular untyped $\lambda$-calculus allow functions to be applied to themselves. This is going to be troublesome, considering domains as sets, as this will be a clear infringement of \emph{ZF Axiom Theory}\cite{kunen2014set}. Namely, the infinite descending sequence
% $$f\ni \{f,f(f)\}\ni f \ni \{f,f(f)\}...$$
% in contradiction with the \emph{regularity axiom}. An approach that seek solving this problems is presented in the next section, starring the introduction of types.  \\

% This last idea, despite being clear and loud to the intuition, is not a proof of inconsistency as there is no need for domains to be sets. Nonetheless, there was another problem that is to be deal that was noticed before. $\lamdba$-calculus was proposed to be a deductive system. The  \emph{Kleene-Rosser paradox}, first exhibited in \cite{kleene1935inconsistency} proved that simply typed $\lambda$-calculus is inconsistent. This paradox was perfected in 1958 by Curry \cite{curry1958combinatory} with the so called \emph{Curry's paradox}. \\

% To solve these problems, a very natural idea is included: the use of types in our computation system. This idea is very natural nowadays, as nearly everyone learns to program priors to a deep academic career. However, we must not forget that the origin was not to use types because we liked them initially, but because they really allow us to avoid logical problems.  



\section{Typed $\lambda$-Calculus}
\emph{Typed $\lambda$-calculus} is a refinement of untyped $\lambda$-calculus, on which the concept of typing is introduced. We are going to present three aproximation to simply typing: \emph{minimal, basic and extended simply typed }$\lambda$\emph{-calculus}. 

\subsection{Definition}

We synthesize the definitions of typing presented in \cite{lambek1988introduction} or \cite{selinger2008lecture}. We structure this definition in three steps: types, terms  and equations.


\begin{definition}
  The types of basic simply typed $\lambda$-calculus are built via the BNF:
  $$A,B ::= \iota |\ A\to B\ |\ A \times B  \ |\ 1.$$
  where $\iota$ denote a basic type. 
\end{definition}
\begin{remark}
  We usually refer to basic simply typed $\lambda$-calculus as simply typed $\lambda$-calculus.
\end{remark}


% Lets start laying some bricks useful for the intuition. $\iota$ type is foundational type. We consider also the type $1$. Others author, such as \cite{lambek1988introduction} prefer to include a type for every natural. Nonetheless, we consider that we can repeat the construction realized in untyped lambda-calculus to consider this typing. \\


As it happens in sets, where we have that we can consider the set of functions between two set, here we can consider the type of function between two types. This types are called \emph{function types}.\\




\begin{definition}
  The \emph{raw terms} of basic simply typed $\lambda$-calculus are built via the BNF:
  $$A,B ::= x\ |\ AB\ |\ \lambda x^t.A \ |\ \langle A,B \rangle\ |\ \pi_1A\ |\ \pi_2A\ |\ *.$$
  where $x$ denote any variables, and $t$ denote any type. 
\end{definition}
\begin{definition}
  We say that a term is closed if it has no free variables.
\end{definition}
\begin{remark}
  We avoid the meticulous redefinition of free and bounded variable and use the one that naturally translates from untyped lambda calculus.
\end{remark}


The main difference with untyped calculus, is that every bound variable has a type. That is, for the expression $(\lambda x^t.M)N$ to be coherent we require $N$ to be of type $t$. This led us to require some sort of condition to $N$ for being of type $t$.\\

Nonetheless raw terms have some other meaningless terms, such as projections of a non-pair $\pi_1(\lambda x^t.x)$. We solve all this problems at once with the \emph {Typing rules}. This rules will restricts the semantics of terms. We start by defining \emph{typing context}.

\begin{definition}
  We state by $M:t$  that a term $M$ is of type $t$. A typing context is a set of assumption $\Gamma = (x_1:A_1)$, on which we assume each variable $x_i$ to be of type $A_i$.
\end{definition}

\begin{remark}
  From this definition, we can state the typing rules, from which we will be able to provide typing. We use the notation $\Gamma \vdash M:A$ meaning that the typing context $\Gamma$ derives in term $M$ being of type $A$. 
\end{remark}


\begin{definition}[Typing Rules]\label{def:typing-rules}
  We define the following typing rules, for each typing context $\Gamma$.
  \begin{itemize}
  \item Every variable is of the type marked by the context, namely:
    $$  (var)\qquad  {\displaystyle \over \Gamma \vdash x_i:A_i},\qquad  i=  1,..,n.$$
    In addition,  $*$ is of type 1.
    $$  (*)\qquad  {\displaystyle \over \Gamma\vdash *:1}.$$

  \item From a term of type $A\to B$ we can derive a term of type $B$, from a term of type $A$:
    $$(app)\qquad  {\displaystyle \Gamma \vdash M:A\to B\qquad \Gamma \vdash N:A      \over \Gamma \vdash MN:B}.$$
    Conversely, we can deduce th
    $$(abs)\qquad  {\displaystyle \Gamma, x: A\vdash M: B  \over \Gamma \vdash \lambda x^A.m:A\to B}.$$
  \item The projections takes types pairing to each typing:
    $$(\pi_i) \qquad {\displaystyle \Gamma\vdash M: A_1\times A_2 \over \Gamma \vdash \pi_i M: A_i},\qquad i=1,2,$$
    and conversely:
    $$(pair) \qquad {\displaystyle \Gamma\vdash M: A\qquad \Gamma\vdash N: B \over \Gamma \vdash \langle M, N\rangle:  A\times B}.$$
  \end{itemize}
\end{definition}



\begin{remark}
  Not every term can be typed, namely the two previous examples of bad-behaviour: $\pi_1(\lambda x^t. x)$ and $(\lambda x^t.M)N$ where $N$ is not of type $t$. Thus, in simply typed $\lambda$-calculus, we only work with typed terms.
\end{remark}

\begin{definition}
  The terms of \emph{basic simply typed $\lambda$-calculus} is a raw typed $\lambda$-term that, together with a typing context of every variable, is subject to be typed.
\end{definition}
\begin{remark}
  Typing rules are often called \emph{term-forming operation}. As the only terms that we consider are those suitable to be typed, we can see these typing rules as rules to construct terms inductively.
\end{remark}

By assigning type we mean assigning types to the free and bound variables. Further on, when talking about terms we will refer to simply type $\lambda$-terms. On these terms, we can define substitution just like we defined it on untyped $\lambda$-calculus.


\subsection{Reductions in simply typed $\lambda$-calculus}

To talk Church-Rosser, we have to talk reduction. Reductions are basically the same but for the additional structure added that we need to respect: 

\begin{definition}[Section 2.5 \cite{selinger2008lecture}]
  We define the \emph{single-step} $\beta$\emph{-reduction} as the smallest relationship $\to_\beta$ such that:
  \begin{itemize}
  \item[]$(\beta)$: $ (\lambda x^t.M)N \to_\beta M[N/x]$.\\
  \item[]$(\beta_{\times,i})$: $\pi_i\langle M_1,M_2\rangle \to_\beta M_i$.\\
  \item[]$(\operatorname{cong}_1)$: If $ M \to_\beta M'$ then $MN \to_\beta M'N$.\\
  \item[]$(\operatorname{cong}_2)$: If $ N \to_\beta N'$ then $ MN \to_\beta MN'$.\\
  \item[]$(\zeta)$: If $M\to_\beta M'$ then $(\lambda x^t.M) \to_\beta \lambda x^t.M'$.\\
  \end{itemize}
  We define the \emph{multiple-step} $\beta$\emph{-reduction} $\twoheadrightarrow_\beta$ as the reflexive, transitive closure of $\to_\beta$.
\end{definition}

\begin{definition}
  We define the single-step $\eta$-reduction $\to_\eta$ as the smallest relationship such that: 
  \begin{itemize}
  \item[]$(\eta)$: $(\lambda x^t.Mx) \to_\eta M}$,para todo $ x \not  \in FV(M)$.\\
\item[]$(\eta_1)$: $\langle\pi_1 M, \pi_2 M\rangle\to_\eta M$.\\
\item[]$(\eta_\times)$: If $M:1$ then $M \to_\eta *$ . \\
\item[]$(\operatorname{cong}_1)$: If $ M \to_\eta M'$ then $MN \to_\eta M'N$.\\
\item[]$(\operatorname{cong}_2)$: If $ N \to_\eta N'$ then $ MN \to_\eta MN'$.\\
\item[]$(\zeta)$: If $M\to_\eta M'$ then $(\lambda x.M) \to_\eta \lambda x.M'$.\\
\end{itemize}

Similarly, we define the multiple-step $\eta$-reduction $\twoheadrightarrow_\eta$ as the transitive reflexive closure of $\to_\eta$, and the $\eta$-equivalence as the symmetric closure of $\twoheadrightarrow_\eta$.
\end{definition}

\begin{remark} Note that we basically just add new rules so that $\beta$ and $\eta$ reductions pair with the new syntax provided by the product.
\end{remark} 
We can now talk about about Church-Rosser.  Lets check that it does not hold. For example, if $x: A\times 1$ then we can consider $M=\langle \pi_1x, \pi_2x\rangle$. Because of the rule $\eta_1$, we have that $M \to_{\eta}\langle \pi_1 x, *\rangle$, but taking $\eta_\times$ into account we can check that $M \to_{\eta} x$. \\

Despite this, $\beta$-reduction does maintain the Church-Rosser property, so from a computational point of view there is no problem at all. 

\subsection{Minimal and Expanded Typing}
\subsubsection{Minimal Typing}
The already explained $\lambda$-calculus can be reduce to a slimmer version. In fact, the only type truly necessary are the function types. We present it succinctly.

\begin{definition}
  The types of minimal simply typed $\lambda$-calculus are built via the BNF:
  $$A,B ::= \iota |\ A\to B.$$
  where $\iota$ denote a basic type. 
\end{definition}



\begin{definition}
  The raw term of minimal simply typed $\lambda$-calculus are built via the BNF:
  $$A,B ::= x\ |\ AB\ |\ \lambda x^t.A.$$
  where $x$ denote any variables, and $t$ denote any type. 
\end{definition}



\begin{definition}[Typing Rules]\label{def:typing-rules}
  We define the following typing rules, for each typing context $\Gamma$.
  \begin{itemize}
  \item Every variable is of the type marked by the context, namely:
    $$  (var)\qquad  {\displaystyle \over \Gamma \vdash x_i:A_i},\qquad  i=  1,..,n.$$

  \item From a term of type $A\to B$ we can derive a term of type $B$, from a term of type $A$:
    $$(app)\qquad  {\displaystyle \Gamma \vdash M:A\to B\qquad \Gamma \vdash N:A      \over \Gamma \vdash MN:B}.$$
    Conversely, we can deduce th
    $$(abs)\qquad  {\displaystyle \Gamma, x: A\vdash M: B  \over \Gamma \vdash \lambda x^A.m:A\to B}.$$
  \end{itemize}
\end{definition}

\begin{definition}
  The terms of minimal simply typed lambda calculus are the raw terms that are subject to being typed under a certain Type context.
\end{definition}
\begin{remark}
  We have simply trimmed the fundamental part of the basic definition.
\end{remark}
\subsubsection{Expanded Typing}
We can add to the definition of typing by considering the sum Type. The idea is to have two types $A$ and $B$ and be able to consider a term $\lambda x^{A+B}. x+1$. That is, we can consider two types to be acceptable by a function. 

\begin{definition}
  The types of expanded simply typed $\lambda$-calculus are built via the BNF:
  $$A,B ::= \iota |\ A\to B\ |\ A \times B \ |\ A + B  \ |\ 1\ |\ 0.$$
  where $\iota$ denote a basic type. 
\end{definition}

We proceed to define the raw typed $\lambda$-terms.

\begin{definition}
  The raw terms of expanded simply typed $\lambda$-calculus are built via the BNF:
  \begin{align*}
    A,B, C ::= x\ &|\ AB\ |\ \lambda x^t.A \ |\ \langle A,B \rangle\ |\ \pi_1A\ |\ \pi_2A\ |\ * \\
                  &|\ \iin_1 A\ |\ \iin_2 A \ |\ \ccase A ; x^{t_1}.B\oo x^{t_2}.C \ |\ \square^t. 
  \end{align*}
  where $x$ denote any variables, and $t$ denote any type. 
\end{definition}

The term $\ccase A ; x^{t_1}.B\oo x^{t_2}.C$ abstracts the idea of a function on  an union term behaves differently in each type that is included. In the typing laws we will see that it is necessary that the type returned by the application of a variable in a function of type union must always converge to the same type ($case$ rule).\\

For this typing, three new rules are included for type derivation, in addition to the previously defined in \ref{def:typing-rules}:
\begin{definition}[Typing Rules]
  We define the following typing rules, for each typing context $\Gamma$.
  \begin{itemize}
  \item Every type is part of a union type including it:
    $$  (\iin_i)\qquad  {\displaystyle\Gamma \vdash M:A_i \over \Gamma \vdash \iin_i M:A_1+A_2},\qquad  i=  1,2.$$
    conversely, A term on a union must always have the same type after application.:
    $$(\ccase) \qquad {\displaystyle \Gamma\vdash M: A+B\qquad \Gamma, x:A\vdash N: C\qquad \Gamma, x:B\vdash P: C \over \Gamma \vdash \ccase A ; x^{A}.M\oo x^{B}.P:C}.$$
  \item The $\square^\cdot$ extract a term of any type form the void type.
    $$  (\square)\qquad  {\displaystyle\Gamma \vdash M:0 \over \Gamma \vdash \square^A M:A}.$$
  \end{itemize}
\end{definition}

We have the same consideration as previously, so that only those being subject to typing will be considered terms. Unification of typing considerations also holds.
\begin{definition}
  The terms of expanded simply typed lambda calculus are the raw terms that are subject to being typed under a certain Type context.
\end{definition}
\subsubsection{Pure and impure typed $\lambda$-calculus}

We have seen that a typing context can vary which terms are subject to be formed and which does not. This consideration will be important later in our discussion, when we consider the category of $\lambda$-calculus. In this sense, we can assume that, associated with each typing context, a different lambda computation is generated. This distinction inspires the following definition.


\begin{definition}
  A basic (resp. minimal, extended) lambda calculus is a triple $(\Xi, \Lambda, \Gamma)$ such that:
  \begin{itemize}
  \item $\Xi$ is the collection of types,
  \item $\Lambda$ is the collection of terms,
  \item $\Gamma$ is a typing context,
  \end{itemize}
  where all rules of basic (resp. minimal, extended) lambda calculus are satisfied. When there
  exists no more types and terms that those derived from the definition, and $\Gamma=\{\}$, it is called a \emph{pure basic (resp. minimal, extended) lambda calculus}.   
\end{definition}
\begin{remark}
  Often, in a lambda calculus, is usual to consider terms up to $\alpha\beta\eta$-equivalence. 
\end{remark}

The way to generate a new lambda calculus, is to create a new type $t$, (often, based on other types), and to create a (possibly abstract) new term $M$ with typing context $\{M:t\}$.
\subsection{Unification of typing}

We can consider two standards in typing: \emph{Church Style} and \emph{Curry Style}.
\begin{itemize}
\item Church style,  first shown in \cite{church1940formulation}, is an explicit system, as we do only consider expression with well defined types, in the same way that a function is consider with regard to it domain and codomain. In summary, the typing of a function is the first part of the definition of it, so you can define $f:(0,1)\to (0,1)$ and just then define $f(x)=1/x$. This domain is not it only possible domain, but it what we choose it to be. 
\item Curry style on the other hand, gain some of the notions of untyped $\lambda$-calculus and consider expression as function. To continue the real function analogy, it consider that the function $f(x)=x^2$ just exists, and one can check that it is well defined on $\R$. \\
\end{itemize}
More information about the typing style can be found on Chapter 10 and 11 of \cite{hindley2008lambda}. \\

Despite this apparent differences, both typing styles can be \emph{unified}. An unifier is a pair of substitution that makes two type styles equal as typed templates. Such an unifier is based onta an algorithm based on type inference. This is instrumental to languages  as relevant \texttt{python}, that works with implicit typed variables. How this algorithms for unification is shown in great detail in chapter 9  of \cite{selinger2008lecture}. Due to this unification, we can consider only explicitely typed terms without any remorse.

\section{Curry-Howard bijection}
\subsection{Natural deduction}
In this section we succinctly introduce the notation of propositional intuitionistic logic, in order to work with them further in the chapter. As we will discuss them in more depth the deduction system in next chapter, we spare our readers of yet another comprehensive introduction of the widely known intuitional propositional logic. Should it be required, more information of propositional logic can be found in, for example, \cite{marek2009introduction} and \cite{wadler2015propositions}. Natural deduction originally appears in the works of \cite{gentzen1935untersuchungen}.In this section, we present the more general form. \\

Thorough this section we replicate notations and process done when defining typed $\lambda$-calculus. This is done purposely, as our aim is to proof an equivalence between both system. We start by considering the alphabet consisting a set of countable many variables $x,y,z,...$ as done previously in lambda-calculus, $\top$ and $\bot$ 

\begin{definition}
  The formulas of propositional intuitionistic logic are built via the BNF:
  $$A,B ::= x |\ A\to B\ |\ A \land B \ |\ A \lor B \ |\ \top \ |\ \bot .$$
  where $x$ denote any variable.
\end{definition}




Having the syntax done, is time to provide meaning. We want $\top$ to be the truth value. A formula is true if $\top \to A$. Conversely, a formula is \emph{not-true} or \emph{false} (sometimes denoted as $\neg A$) if $ A \to \bot$. In addition, we want all the formulas from which we can derive certain to be true. For this we will define, analogously to the typing-contex from the previous chapter, what a \emph{truth-assumption} is and  what the rules of deduction are.

\begin{definition}
  A truth-assumption is a set of variables $\Gamma = \{x_1,...,x_n\}$ that we assume to be true. An \emph{judgement} $\Gamma \vdash B$ states that from truth assumption $\Gamma$, the formula $B$ can be deduced to be true. 
\end{definition}

Sometimes we can write a truth assumption $\Gamma, A$, that will denote that additionally $A$ is assume to be true. As most times, we will only need a formula $A$ to be true or not without any interest on what exact variable configuration made this possible, so by abuse of notation we can consider $\Gamma = \{x_1,A_1\}$ to have both variables and formulas.  
\begin{definition}[Deduction Rules]
  We define the following deduction rules, for each truth assumption Gamma $\Gamma=\{x_1,...,x_n\}$.
  \begin{itemize}
  \item Every variable assumed to be true is true:
    $$  (ax)\qquad  {\displaystyle \over \Gamma \vdash x_i},\qquad \forall i \in 1,..,n.$$
    In addition, $\top$ is always true:
    $$  (\top)\qquad  {\displaystyle \over \Gamma \vdash \top}.$$
  \item From a true formula $A\to B$ and a true formula $A$, $B$ can be derived:
    $$(\to_1)\qquad  {\displaystyle \Gamma \vdash A \to B\qquad \Gamma \vdash A      \over \Gamma \vdash B}.$$
    Conversely, if assuming $A$ deduces $B$, then $A\to B$ is true.
    $$(\to_2)\qquad  {\displaystyle \Gamma, A \vdash B      \over \Gamma \vdash (A\to B)}.$$
    
  \item The conjunction being true imply each element to be true:
    $$(\land_1) \qquad {\displaystyle \Gamma\vdash A_1\land A_2 \over \Gamma \vdash A, \qquad \Gamma \vdash B },$$
    and conversely:
    $$(\land_2) \qquad {\displaystyle \Gamma\vdash A\qquad \Gamma\vdash B \over \Gamma \vdash  A \land B}.$$
  \item An element being true implies the union being true:
        $$  (\lor_1^i)\qquad  {\displaystyle\Gamma \vdash A_i \over \Gamma \vdash A_1+A_2},\qquad  i=  1,2.$$

    Every type is part of a union type including it:
    $$  (\lor_1^i)\qquad  {\displaystyle\Gamma \over \Gamma A_i  \vdash A_1+A_2},\qquad  i=  1,2.$$
    conversely, A term on a union must always have the same type after application.:
    $$(\lor_2) \qquad {\displaystyle \Gamma\vdash A\lor B\qquad \Gamma, A\vdash C\qquad \Gamma, B\vdash C \over \Gamma \vdash C}.$$
  \item the \emph{ex falsum quodlibet} (i.e. everything is derivable from falsity)  holds:
    $$  (\bot)\qquad  {\displaystyle\Gamma \vdash \bot \over \Gamma \vdash A}.$$ 

  \end{itemize}
\end{definition}



Note that we consider a logic without law of excluded middle. This approach, although somewhat demodÃ© in modern mathematics, was highly popular at the beginning of the twentieth century. It sought to solve the problems of mathematical foundations, in particular the \emph{principle of explosion}. \\


To work with this logic, we usually work in the usual \emph{truth derivation}. That is, having a formula $F$, we use the previously introduced rules in other to see whether can they be derivated from the truth assumption. More often than not, we consider the empty assumption, therefore we are working with \emph{tautologies}

\begin{example}
  We can consider the formula $F=((x\to y) \land (y\to z)) \to ((x \to z)$ and $\Gamma$ the empty assumption. Then we can deduce:
  \begin{align*}
    \Gamma=\{\}& \vdash    ((x\to y) \land (y\to z)) \to (x\to z),\\
    \Gamma=\{(x\to y)\land (y\to z)\} & \vdash    (x \to z),\\
    \Gamma=\{(x\to y), (y\to z)\} & \vdash    (x \to z),\\
    \Gamma=\{ (y\to z)\} & \vdash    (y \to z),\\
    \Gamma=\{\} & \vdash \top.
  \end{align*}
  therefore the formula $F$ is true.
\end{example}





As a final note, the definitions of intuitionistic logic and $\lambda$-calculus introduced in this work, are made to be matching but are not unique. For example, other source consider that the types of simply typed $\lambda$-calculus (instead of the extended typing) and consider only (as is done in \cite[Section 6.5]{selinger2008lecture}):
$$A,B ::= x |\ A\to B\ |\ A \land B \ |\ \top .$$

This is called \emph{positive intuitionistic calculus}. In the next chapter we are going to define the concept of \emph{deduction system} and from it, grow into the different approaches to logic.

% We decided not to follow this line, which is equally valid, for consistency with \cite{seely1984locally} However, it is useful to have this consideration resolved from the beginning, especially for engineering applications.


\subsection{Bijection}
The first approach of $\lambda$-calculus to be seen as a deduction system was observed by Curry in 1934\cite{curry1934functionality}, early in the development of this area and was completed by Howard in 1980 \cite{howard1980formulae}. \\% {\color{red} AÃ±adir un poquito de introducciÃ³n histÃ³rica que no cuesta na.}\\


Having already asked ourselves when does a term have a type, it is natural to arise the new question: When does a type have a term? This is in fact the fundamental idea of the Curry-Howard isomorphism. For example, considering whether it exists a term for the type$(A \times B) \to B$, is analogue to consider the formula $(A\land B)\to B$ to be a tautology. Moreover, the term $\lambda x^{A\times B}. \pi_2 x$ can be seen as a proof of the tautology! we have arrived at the dream of a constructivist mathematician: computational algorithms are demonstrations, and demonstrations are nothing if not algorithms. Lets formalize this intuition.\\


We can create a pairing between type and formulas by pairing variables with variables and:
\begin{table}[!h]
  \begin{center}
    \begin{tabular}{|l|c|c|}
      \hline
      Typing name & Types  & Formulas  \\
      \hline
      Minimal     & Function type $\to$   & Implication $\to$  \\
      \hline 
      Basic      & Type 1 & $\top$ \\
                  & Product type $\times$ & Conjuction $\land$ \\
      \hline
      Expanded   & Type 0 & $\bot$ \\
                  & Sum type $+$     & Disjuction $\lor$ \\
      \hline
    \end{tabular}
    \caption*{\label{tab:table-name} Pairing of formulas and terms.}
  \end{center}
\end{table}

And we can see that this pairing holds because we can see that Typing rules 

\begin{itemize}
\item We pair the concept of a formula being true with the concept of a type having a term. We formalize this by pairing truth assumption $\Gamma=\{A\}$ is with the typing context $\Gamma\vdash M:A$. 
\item We can pair $(var)$ with $(ax)$ and $(*)$ with $(\top)$.
\item We can pair $(app)$ with $(\to_1)$ and $(abs)$ with $(\to_2)$.
\item We can pair $(\pi_i)$ with $(\land_1)$ and $(\land_2)$ with $(pair)$.
\item We can pair $(\iin_i)$ with $(\lor_1^i)$ and $(\lor_2)$ with $(\ccase)$.
\item We can pair $0$ with $\bot$.
\end{itemize}


Finally, we pair the terms  with the truth derivations. That is, given a term $M$  of type $C$ with associated formula $F$. By replacing each typing rule needed to deduce $M:C$  with an associated derivation rule, we can get a truth derivation, and conversely with a truth derivation of $F\to \top$ from $\Gamma=\{\}$.\\

From this pairing we can define different ...

\section{Lambda calculus as a computation system}
% TODO: Expand this section properly. 
Around 1930, people start thinking about what mean for a function to be computable. There were three major answer to this question (section 4, \cite{cardone2006history}):
\begin{itemize}
\item In 1930s Alonzo Church introduces the notion of $\lambda$-calculus, in which a function is computable if we can write it as a recursive-lambda term onto Church's numerals, that is, if we can deduce the result after a (hopefully finite) deduction steps.
\item Later, Alan Turing, who had previously been a doctoral student of Alonzo Church, developed the concept of the Turing machine, in which a function is computable if a tape machine with a limited set of operations is capable of reproducing it.
\item Meanwhile, GÃ¶del define the computable function as the minimum set of function such that some properties (such as the existence of a successor function) are includes, and is closed under some operations. 
\end{itemize}

The goal of this three mathematicians was to solve the Entscheidungsproblem\cite{hilbert1999principles}.\\

The interest for this type of problems was clear for the mathematical community as the goal was to propose an algorithm that solve every theorem and can be computed. The Church-Turing thesis fromally proved that these three independently generated notions were in fact equivalent\cite{copeland1997church}.\\


This thesis is also formulated in a philosophical background, to state that every effective computable function system is equivalent to those three. While it can not be formally proven, it has near-universal acceptance to date. Any computing system that can replicate, and thus is equivalent, to either Turing Machines Calculus or $\lambda$-Calculus is said to be \emph{Turing Complete}.\\

Nonetheless, after the formalization of the solution of this problem there were a last problem that was not adverted: the finiteness of time. SAT is the problem that has as input a propositional logic formula and solve whether it is satisfiable. This problem is NP-complete, quite famously the firs of these problems\cite{cook1971complexity}. If we consider the analogous problem for first order algebra, we have an even more complex P-space-complete problem, being almost intractable in worst cases to this date. As a happy consequence for us, much work is left to be done in this area \cite{cook2006p}. 

